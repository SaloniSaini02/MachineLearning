{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total points for this HW: 100.\n",
    "\n",
    "Please note: Copying and pasting other people's work is absolutely prohibited.  Any such cases will be reported to CUSP's education team and severely punished. Discussion is encouraged, and feel free to exchange ideas with your classmates, but please write your own code and do your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1: Accuracy and interpretability (10 pts)\n",
    "\n",
    "a) Describe a real-world prediction problem using urban data for which _interpretability_ of your models and results is essential, and for which it might be preferable to use decision trees rather than random forests.  Argue why this is the case. (3 pts)\n",
    "\n",
    "\n",
    "One advantage of decision tree is that it is easy to interpret the results. Whereas their disadvantage is that they tend to overfit especially when the dataset is large or there are numerous features. A real world example is a classification problem to diagnose a medical condition based on symptoms of patients.The features would be the conditions of the patient like blood pressure or heart rate and the model predicts a diagnosis of the patient.In such problems  interpretabilty of the model and result is essential beacuse it allows us to verify how the model will take decisions for previosly unseen data.Interpretabilty is important in healthcare because the models are being used for patient care and it will help understand the diagnosis, treatment options and make better decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe a real-world prediction problem using urban data for which _accuracy_ is paramount and interpretability may be less important, and for which it might be preferable to use random forests rather than decision trees.  Argue why this is the case. (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here.\n",
    "\n",
    "Random Forest is a collection of decision trees whose results are averaged. Random Forests typically give a better performance than decision trees. However they cannot be visualized easily. A real world example is a regression problem to predict the house prices in a city. The features can be the number of rooms, gross area, location etc. An application of such a model is that it can be for house valuation and to make investments in real estate. Hence accuracy of the model (to make investments) is more important than interpretability of the model for companies. Also a lot of factors determine the price of a house it's features, environment, location.Random forest rather than decision trees will average the result of the n_estimators to reduce bias and error that would be present in a single model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let's imagine that you want to try to get the best of both worlds (accuracy _and_ interpretability).  So you decide to start by learning a random forest classifier.  Describe at least one way of getting some interpretability out of the model by post-processing.  You could either pick a method from the literature (e.g., Domingos's work on combining multiple models or some method of computing variable importance), or come up with your own approach (doesn't have to be ground-breaking, but feel free to be creative!) (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here.\n",
    "\n",
    "A way of improving interpretabilty of ensemble models has been presented in a paper by Santoshi Hara and Kohei Hayashi. It states that the interpretabilty for ensemble models is low becuase it divides the input space into too many regions. It suggests creating two models. One is the prediction model that is the original ensemble method and the second is the interpretation model that represeants the first model with lesser regions. The interpretation model is modelled after the predcition model using EM algorithm and KL diversgence is used for optimization. This post processing model gave a good approximation of ensemble models on synthetic data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2: Build a decision tree for classification, step by step, following the lecture notes. Note that the dataset has been slightly modified, so you will get a different tree than the one shown in the lecture notes.  (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>HP</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>175</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>139</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>190</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>145</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>170</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MPG  cylinders   HP   weight\n",
       "0   good          4   75    light\n",
       "1    bad          6   90   medium\n",
       "2    bad          4  110   medium\n",
       "3    bad          8  175  weighty\n",
       "4    bad          6   95   medium\n",
       "5    bad          4   94    light\n",
       "6    bad          4   95    light\n",
       "7    bad          8  139  weighty\n",
       "8    bad          8  190  weighty\n",
       "9    bad          8  145  weighty\n",
       "10   bad          6  100   medium\n",
       "11  good          4   92   medium\n",
       "12   bad          6  100  weighty\n",
       "13   bad          8  170  weighty\n",
       "14  good          4   89   medium\n",
       "15  good          4   65    light\n",
       "16   bad          6   85   medium\n",
       "17  good          4   81    light\n",
       "18   bad          6   95   medium\n",
       "19   bad          4   93    light"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from StringIO import StringIO\n",
    "thefile = StringIO('MPG,cylinders,HP,weight\\ngood,4,75,light\\nbad,6,90,medium\\nbad,4,110,medium\\nbad,8,175,weighty\\nbad,6,95,medium\\nbad,4,94,light\\nbad,4,95,light\\nbad,8,139,weighty\\nbad,8,190,weighty\\nbad,8,145,weighty\\nbad,6,100,medium\\ngood,4,92,medium\\nbad,6,100,weighty\\nbad,8,170,weighty\\ngood,4,89,medium\\ngood,4,65,light\\nbad,6,85,medium\\ngood,4,81,light\\nbad,6,95,medium\\nbad,4,93,light')\n",
    "df = pd.read_csv(thefile)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please use numpy and pandas to do the computation for parts a) through f).  Do not use an existing decision tree implementation like sklearn for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Start with the entire dataset and find the most common MPG value. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "countG=0\n",
    "countB=0\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i,'MPG']==\"good\":\n",
    "        countG=countG+1\n",
    "    else:\n",
    "        countB=countB+1\n",
    "MPG_value=\"bad\" if countG>countB else \"bad\"\n",
    "MPG_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPG_value=df['MPG'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGain(goodY,badY,goodN,badN):\n",
    "    def F(X,Y):\n",
    "        val1 = X*np.log2(1.*(X+Y)/X) if X>0 else 0\n",
    "        val2 = Y*np.log2(1.*(X+Y)/Y) if Y>0 else 0\n",
    "        return val1+val2\n",
    "    return (F(goodY+goodN,badY+badN)-F(goodY,badY)-F(goodN,badN)) / (goodY+goodN+badY+badN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Enumerate all the possible binary questions you could ask for each discrete-valued variable.  For each such split, compute the numbers of \"good\" and \"bad\" MPG vehicles in each of the two child nodes, and compute the information gain using the provided function above. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "maintain_splits={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_discrete(df,column_name,split_value):\n",
    "    goodY=((df[column_name] == split_value) & (df['MPG']== 'good')).sum()\n",
    "    badY=((df[column_name] == split_value) & (df['MPG']== 'bad')).sum()\n",
    "    goodN=((df[column_name]!= split_value) & (df['MPG']== 'good')).sum()\n",
    "    badN=((df[column_name] != split_value) & (df['MPG']== 'bad')).sum()\n",
    "    ig=InformationGain(goodY,badY,goodN,badN)\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=['cylinders','weight']\n",
    "def find_best_split_discrete(df,column_names):\n",
    "    max_ig=0\n",
    "    column=\"\"\n",
    "    max_split=0\n",
    "    for column_name in column_names:\n",
    "        split_values=df[column_name].unique()\n",
    "        for split_value in split_values:\n",
    "            ig=split_discrete(df,column_name,split_value)\n",
    "            if ig>max_ig:\n",
    "                max_ig=ig\n",
    "                column=column_name\n",
    "                max_split=split_value\n",
    "            print(\"Column_name : \" + column_name + \" Split value: \" + str(split_value) + \" IG: \" +str(ig))\n",
    "    return (max_ig,column,max_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_name : cylinders Split value: 4 IG: 0.365293897532\n",
      "Column_name : cylinders Split value: 6 IG: 0.15307795339\n",
      "Column_name : cylinders Split value: 8 IG: 0.122556248918\n",
      "Column_name : weight Split value: light IG: 0.0971071794515\n",
      "Column_name : weight Split value: medium IG: 8.881784197e-17\n",
      "Column_name : weight Split value: weighty IG: 0.15307795339\n"
     ]
    }
   ],
   "source": [
    "#max_ig,column,max_split=find_best_split_discrete(column_names)\n",
    "max_ig,column,max_split=find_best_split_discrete(df,column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Enumerate all the possible binary questions you could ask for the real-valued variable HP.  For each such split, compute the numbers of \"good\" and \"bad\" MPG vehicles in each of the two child nodes, and compute the information gain using the provided function above. (5 pts) \n",
    "\n",
    "NOTE: if you'd like, you can just use all midpoints between consecutive values of the sorted HP attribute.  You are not required to exclude provably suboptimal questions like we did in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_real(df,column_name,split_value):\n",
    "    goodY=((df[column_name] > split_value) & (df['MPG']== 'good')).sum()\n",
    "    badY=((df[column_name] > split_value) & (df['MPG']== 'bad')).sum()\n",
    "    goodN=((df[column_name] <=  split_value) & (df['MPG']== 'good')).sum()\n",
    "    badN=((df[column_name] <= split_value) & (df['MPG']== 'bad')).sum()\n",
    "    ig=InformationGain(goodY,badY,goodN,badN)\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "column_name='HP'\n",
    "def find_best_split_real(df,column_name,max_ig,column,max_split):\n",
    "    li=sorted(df[column_name])\n",
    "    for i in range(len(li)-1):\n",
    "        mid=np.round((li[i]+li[i+1])/2)\n",
    "        ig=split_real(df,column_name,mid)\n",
    "        if ig>max_ig:\n",
    "            max_ig=ig\n",
    "            column=column_name\n",
    "            max_split=mid\n",
    "        print(\"Column_name : \" + column_name + \" Split value: \" + str(mid) + \" IG: \" +str(ig))\n",
    "    return (max_ig,column,max_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_name : HP Split value: 70 IG: 0.105914933394\n",
      "Column_name : HP Split value: 78 IG: 0.226257944976\n",
      "Column_name : HP Split value: 83 IG: 0.367102656103\n",
      "Column_name : HP Split value: 87 IG: 0.214170945008\n",
      "Column_name : HP Split value: 89 IG: 0.365776599471\n",
      "Column_name : HP Split value: 91 IG: 0.275926745594\n",
      "Column_name : HP Split value: 92 IG: 0.509185925461\n",
      "Column_name : HP Split value: 93 IG: 0.429504523289\n",
      "Column_name : HP Split value: 94 IG: 0.365293897532\n",
      "Column_name : HP Split value: 95 IG: 0.223356870468\n",
      "Column_name : HP Split value: 95 IG: 0.223356870468\n",
      "Column_name : HP Split value: 97 IG: 0.223356870468\n",
      "Column_name : HP Split value: 100 IG: 0.15307795339\n",
      "Column_name : HP Split value: 105 IG: 0.15307795339\n",
      "Column_name : HP Split value: 124 IG: 0.122556248918\n",
      "Column_name : HP Split value: 142 IG: 0.0944475384315\n",
      "Column_name : HP Split value: 157 IG: 0.0683942335509\n",
      "Column_name : HP Split value: 172 IG: 0.0441134636746\n",
      "Column_name : HP Split value: 182 IG: 0.0213774558499\n"
     ]
    }
   ],
   "source": [
    "max_ig,column,max_split=find_best_split_real(df,'HP',max_ig,column,max_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Based on your results for parts b and c, what is the optimal binary split of the data?  Of the two child nodes created by this split, which (if any) would require further partitioning? (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best split is the one with the highest information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_name : cylinders Split value: 4 IG: 0.365293897532\n",
      "Column_name : cylinders Split value: 6 IG: 0.15307795339\n",
      "Column_name : cylinders Split value: 8 IG: 0.122556248918\n",
      "Column_name : weight Split value: light IG: 0.0971071794515\n",
      "Column_name : weight Split value: medium IG: 8.881784197e-17\n",
      "Column_name : weight Split value: weighty IG: 0.15307795339\n",
      "Column_name : HP Split value: 70 IG: 0.105914933394\n",
      "Column_name : HP Split value: 78 IG: 0.226257944976\n",
      "Column_name : HP Split value: 83 IG: 0.367102656103\n",
      "Column_name : HP Split value: 87 IG: 0.214170945008\n",
      "Column_name : HP Split value: 89 IG: 0.365776599471\n",
      "Column_name : HP Split value: 91 IG: 0.275926745594\n",
      "Column_name : HP Split value: 92 IG: 0.509185925461\n",
      "Column_name : HP Split value: 93 IG: 0.429504523289\n",
      "Column_name : HP Split value: 94 IG: 0.365293897532\n",
      "Column_name : HP Split value: 95 IG: 0.223356870468\n",
      "Column_name : HP Split value: 95 IG: 0.223356870468\n",
      "Column_name : HP Split value: 97 IG: 0.223356870468\n",
      "Column_name : HP Split value: 100 IG: 0.15307795339\n",
      "Column_name : HP Split value: 105 IG: 0.15307795339\n",
      "Column_name : HP Split value: 124 IG: 0.122556248918\n",
      "Column_name : HP Split value: 142 IG: 0.0944475384315\n",
      "Column_name : HP Split value: 157 IG: 0.0683942335509\n",
      "Column_name : HP Split value: 172 IG: 0.0441134636746\n",
      "Column_name : HP Split value: 182 IG: 0.0213774558499\n",
      "The optimal split is as follows\n",
      "Column_name  HP\n",
      "Split value  92\n",
      "Information Gain  0.509185925461\n"
     ]
    }
   ],
   "source": [
    "max_ig,column,max_split=find_best_split_discrete(df,['cylinders','weight'])\n",
    "max_ig,column,max_split=find_best_split_real(df,'HP',max_ig,column,max_split)\n",
    "print(\"The optimal split is as follows\")\n",
    "print(\"Column_name  \" + column)\n",
    "print(\"Split value  \" + str(max_split))\n",
    "print(\"Information Gain  \" + str(max_ig))\n",
    "maintain_splits[column]=max_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_right_node(df,column,max_split):\n",
    "    if column in ['HP']:\n",
    "        goodY=((df[column] > max_split) & (df['MPG']== 'good')).sum()\n",
    "        badY=((df[column] > max_split) & (df['MPG']== 'bad')).sum()\n",
    "        right_df = df.loc[df[column] > max_split]\n",
    "    else:\n",
    "        goodY=((df[column] == max_split) & (df['MPG']== 'good')).sum()\n",
    "        badY=((df[column] == max_split) & (df['MPG']== 'bad')).sum()\n",
    "        right_df = df.loc[df[column] == max_split]\n",
    "    if (goodY==0 or badY==0):\n",
    "        print(\"Right Node needs no more partioning.\")\n",
    "    else:\n",
    "        print(\"Right Node needs to be partitioned further.\")\n",
    "    return right_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Node needs no more partioning.\n",
      "    MPG  cylinders   HP   weight\n",
      "2   bad          4  110   medium\n",
      "3   bad          8  175  weighty\n",
      "4   bad          6   95   medium\n",
      "5   bad          4   94    light\n",
      "6   bad          4   95    light\n",
      "7   bad          8  139  weighty\n",
      "8   bad          8  190  weighty\n",
      "9   bad          8  145  weighty\n",
      "10  bad          6  100   medium\n",
      "12  bad          6  100  weighty\n",
      "13  bad          8  170  weighty\n",
      "18  bad          6   95   medium\n",
      "19  bad          4   93    light\n"
     ]
    }
   ],
   "source": [
    "right_df=create_right_node(df,column,max_split)\n",
    "print(right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_left_node(df,column,max_split):\n",
    "    left_df=pd.DataFrame()\n",
    "    if column in ['HP']:\n",
    "        goodN=((df[column] <=  max_split) & (df['MPG']== 'good')).sum()\n",
    "        badN=((df[column] <= max_split) & (df['MPG']== 'bad')).sum()\n",
    "        left_df = df.loc[df[column] <=max_split]\n",
    "    else:\n",
    "        goodN=((df[column] !=  max_split) & (df['MPG']== 'good')).sum()\n",
    "        badN=((df[column] != max_split) & (df['MPG']== 'bad')).sum()\n",
    "        left_df = df.loc[df[column] != max_split]\n",
    "    if (goodN==0 or badN==0):\n",
    "        print(\"Left Node needs no more partioning.\")\n",
    "    else:\n",
    "        print(\"Left Node needs to be partitioned further.\")  \n",
    "    return left_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Node needs to be partitioned further.\n",
      "     MPG  cylinders  HP  weight\n",
      "0   good          4  75   light\n",
      "1    bad          6  90  medium\n",
      "11  good          4  92  medium\n",
      "14  good          4  89  medium\n",
      "15  good          4  65   light\n",
      "16   bad          6  85  medium\n",
      "17  good          4  81   light\n"
     ]
    }
   ],
   "source": [
    "left_df=create_left_node(df,column,max_split)\n",
    "print(left_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first split perfectly classfies records that are in the right node as bad hence no further partioning is required. The other node has 5 good and 2 bad classifications and will require further partioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Repeat parts a through d until all training data points are perfectly classified by the resulting tree. (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MPG_value=left_df['MPG'].mode()[0]\n",
    "MPG_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_name : cylinders Split value: 4 IG: 0.863120568567\n",
      "Column_name : cylinders Split value: 6 IG: 0.863120568567\n",
      "Column_name : weight Split value: light IG: 0.291691997138\n",
      "Column_name : weight Split value: medium IG: 0.291691997138\n",
      "Column_name : HP Split value: 70 IG: 0.0760098536628\n",
      "Column_name : HP Split value: 78 IG: 0.16958442967\n",
      "Column_name : HP Split value: 83 IG: 0.291691997138\n",
      "Column_name : HP Split value: 87 IG: 0.00597771142377\n",
      "Column_name : HP Split value: 89 IG: 0.0617433579328\n",
      "Column_name : HP Split value: 91 IG: 0.0760098536628\n",
      "The optimal split is as follows\n",
      "Column_name  cylinders\n",
      "Split value  4\n",
      "Information Gain  0.863120568567\n"
     ]
    }
   ],
   "source": [
    "max_ig,column,max_split=find_best_split_discrete(left_df,['cylinders','weight'])\n",
    "max_ig,column,max_split=find_best_split_real(left_df,'HP',max_ig,column,max_split)\n",
    "print(\"The optimal split is as follows\")\n",
    "print(\"Column_name  \" + column)\n",
    "print(\"Split value  \" + str(max_split))\n",
    "print(\"Information Gain  \" + str(max_ig))\n",
    "maintain_splits[column]=max_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Node needs no more partioning.\n",
      "     MPG  cylinders  HP  weight\n",
      "0   good          4  75   light\n",
      "11  good          4  92  medium\n",
      "14  good          4  89  medium\n",
      "15  good          4  65   light\n",
      "17  good          4  81   light\n"
     ]
    }
   ],
   "source": [
    "right_df=create_right_node(left_df,column,max_split)\n",
    "print(right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Node needs no more partioning.\n",
      "    MPG  cylinders  HP  weight\n",
      "1   bad          6  90  medium\n",
      "16  bad          6  85  medium\n"
     ]
    }
   ],
   "source": [
    "left_df=create_left_node(left_df,column,max_split)\n",
    "print(left_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree has been perfectly split using the split cylinders = 4. No further partioning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Draw or show the final decision tree in a format of your choice.  The decision to make at each step and the predicted value at each leaf node must be clear. (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Classify each of the following four vehicles as having \"good\" or \"bad\" fuel efficiency (miles per gallon).  Do this by hand using the tree structure learned in part f. (4 pts)\n",
    "\n",
    "?,8,70,light - bad\n",
    "\n",
    "?,6,113,medium - bad\n",
    "\n",
    "?,4,83,weighty - good\n",
    "\n",
    "?,4,95,weighty - bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3, Predicting burden of disease （40 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>FrxnPeaceIn10</th>\n",
       "      <th>ODA4H2OPcptaDol</th>\n",
       "      <th>RenewResm3PcptaYr</th>\n",
       "      <th>SustAccImprWatRur</th>\n",
       "      <th>SustAccImprWatUrb</th>\n",
       "      <th>SustAccImprSanRur</th>\n",
       "      <th>SustAccImprSanUrb</th>\n",
       "      <th>TotHlthExpPctofGDP</th>\n",
       "      <th>GenGovtPctofTotHlthExp</th>\n",
       "      <th>ExtResHlthPctTotExpHlth</th>\n",
       "      <th>PCptaGovtExpHlthAvgExcRt</th>\n",
       "      <th>GDPPCptaIntDol</th>\n",
       "      <th>AdultLtrcyRate</th>\n",
       "      <th>FemaleLtrcyRate</th>\n",
       "      <th>BurdenOfDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.10891</td>\n",
       "      <td>0.18812</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.15842</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "      <td>0.35644</td>\n",
       "      <td>0.20792</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.94059</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>49</td>\n",
       "      <td>6158</td>\n",
       "      <td>0.85644</td>\n",
       "      <td>0.78713</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>473</td>\n",
       "      <td>0.79208</td>\n",
       "      <td>0.91089</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>71</td>\n",
       "      <td>4860</td>\n",
       "      <td>0.69307</td>\n",
       "      <td>0.60396</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  FrxnPeaceIn10  ODA4H2OPcptaDol  RenewResm3PcptaYr  \\\n",
       "0  Afghanistan            0.1             0.16               2986   \n",
       "1      Albania            1.0             5.58              13306   \n",
       "2      Algeria            0.0             0.33                473   \n",
       "\n",
       "   SustAccImprWatRur  SustAccImprWatUrb  SustAccImprSanRur  SustAccImprSanUrb  \\\n",
       "0            0.10891            0.18812           0.049505            0.15842   \n",
       "1            0.94059            0.98020           0.801980            0.98020   \n",
       "2            0.79208            0.91089           0.811880            0.98020   \n",
       "\n",
       "   TotHlthExpPctofGDP  GenGovtPctofTotHlthExp  ExtResHlthPctTotExpHlth  \\\n",
       "0               0.065                   0.395                   0.4560   \n",
       "1               0.065                   0.417                   0.0340   \n",
       "2               0.041                   0.808                   0.0005   \n",
       "\n",
       "   PCptaGovtExpHlthAvgExcRt  GDPPCptaIntDol  AdultLtrcyRate  FemaleLtrcyRate  \\\n",
       "0                         4             430         0.35644          0.20792   \n",
       "1                        49            6158         0.85644          0.78713   \n",
       "2                        71            4860         0.69307          0.60396   \n",
       "\n",
       "  BurdenOfDisease  \n",
       "0           awful  \n",
       "1             low  \n",
       "2            high  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Burden of diarrheal illness by country.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrxnPeaceIn10</th>\n",
       "      <th>ODA4H2OPcptaDol</th>\n",
       "      <th>RenewResm3PcptaYr</th>\n",
       "      <th>SustAccImprWatRur</th>\n",
       "      <th>SustAccImprWatUrb</th>\n",
       "      <th>SustAccImprSanRur</th>\n",
       "      <th>SustAccImprSanUrb</th>\n",
       "      <th>TotHlthExpPctofGDP</th>\n",
       "      <th>GenGovtPctofTotHlthExp</th>\n",
       "      <th>ExtResHlthPctTotExpHlth</th>\n",
       "      <th>PCptaGovtExpHlthAvgExcRt</th>\n",
       "      <th>GDPPCptaIntDol</th>\n",
       "      <th>AdultLtrcyRate</th>\n",
       "      <th>FemaleLtrcyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.10891</td>\n",
       "      <td>0.18812</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.15842</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "      <td>0.35644</td>\n",
       "      <td>0.20792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.94059</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>49</td>\n",
       "      <td>6158</td>\n",
       "      <td>0.85644</td>\n",
       "      <td>0.78713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>473</td>\n",
       "      <td>0.79208</td>\n",
       "      <td>0.91089</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>71</td>\n",
       "      <td>4860</td>\n",
       "      <td>0.69307</td>\n",
       "      <td>0.60396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>14009</td>\n",
       "      <td>0.39604</td>\n",
       "      <td>0.69307</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.55446</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>22</td>\n",
       "      <td>1942</td>\n",
       "      <td>0.66139</td>\n",
       "      <td>0.53267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2780</td>\n",
       "      <td>0.79208</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.95050</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>11</td>\n",
       "      <td>5697</td>\n",
       "      <td>0.97624</td>\n",
       "      <td>0.97030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FrxnPeaceIn10  ODA4H2OPcptaDol  RenewResm3PcptaYr  SustAccImprWatRur  \\\n",
       "0            0.1             0.16               2986            0.10891   \n",
       "1            1.0             5.58              13306            0.94059   \n",
       "2            0.0             0.33                473            0.79208   \n",
       "3            0.2             0.63              14009            0.39604   \n",
       "4            1.0             2.51               2780            0.79208   \n",
       "\n",
       "   SustAccImprWatUrb  SustAccImprSanRur  SustAccImprSanUrb  \\\n",
       "0            0.18812           0.049505            0.15842   \n",
       "1            0.98020           0.801980            0.98020   \n",
       "2            0.91089           0.811880            0.98020   \n",
       "3            0.69307           0.158420            0.55446   \n",
       "4            0.98020           0.603960            0.95050   \n",
       "\n",
       "   TotHlthExpPctofGDP  GenGovtPctofTotHlthExp  ExtResHlthPctTotExpHlth  \\\n",
       "0               0.065                   0.395                   0.4560   \n",
       "1               0.065                   0.417                   0.0340   \n",
       "2               0.041                   0.808                   0.0005   \n",
       "3               0.028                   0.842                   0.0670   \n",
       "4               0.060                   0.202                   0.1720   \n",
       "\n",
       "   PCptaGovtExpHlthAvgExcRt  GDPPCptaIntDol  AdultLtrcyRate  FemaleLtrcyRate  \n",
       "0                         4             430         0.35644          0.20792  \n",
       "1                        49            6158         0.85644          0.78713  \n",
       "2                        71            4860         0.69307          0.60396  \n",
       "3                        22            1942         0.66139          0.53267  \n",
       "4                        11            5697         0.97624          0.97030  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data.iloc[:,1:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data.iloc[:, -1] = labelencoder.fit_transform(data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "4    2\n",
       "Name: BurdenOfDisease, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "NAME: Burden of diarrheal illness by country\n",
    "\n",
    "SIZE: 130 Countries, 16 Variables\n",
    "\n",
    "VARIABLE DESCRIPTIONS:\n",
    "\n",
    "Country: Country name\n",
    "\n",
    "FrxnPeaceIn10: Fraction of the past ten years in which a country has been at peace \n",
    "\n",
    "ODA4H2OPcptaDol: Per Capita Official Developmental Assistance for water projects\n",
    "\n",
    "RenewResm3PcptaYr: Renewable Water Resources in cubic meters per capita per year\n",
    "\n",
    "SustAccImprWatRur: Fraction of rural population with sustainable access to improved water\n",
    "\n",
    "SustAccImprWatUrb: Fraction of urban population with sustainable access to improved water\n",
    "\n",
    "SustAccImprSanRur: Fraction of rural population with sustainable access to improved sanitation\n",
    "\n",
    "SustAccImprSanUrb: Fraction of urban population with sustainable access to improved sanitation\n",
    "\n",
    "TotHlthExpPctofGDP: Fraction of a country's GDP devoted to health spending\n",
    "\n",
    "GenGovtPctofTotHlthExp: The fraction of total health expenditures for a country which is provided by the government\n",
    "\n",
    "ExtResHlthPctTotExpHlth: The fraction of total health expenditures for a country which is comes from sources external to the country\n",
    "\n",
    "PCptaGovtExpHlthAvgExcRt: Per Capita Government Health Expenditures at the average exchange rate\n",
    "\n",
    "GDPPCptaIntDol: Gross Domestic Product per capita in international dollars\n",
    "\n",
    "AdultLtrcyRate: Adult Literacy rate\n",
    "\n",
    "FemaleLtrcyRate: Female Literacy rate\n",
    "\n",
    "BurdenOfDisease: Our target variable for classification.  The burden of disease due to diarrheal illness, categorized into \"low\", \"medium\", \"high\", and \"awful\" quartiles.  For each country, we have estimates of the number of Disability-Adjusted Life Years lost per 1000 persons per year (DALYs) due to diarrheal illness.  Countries with \"low\" burden of disease have up to 2.75345 DALYs; countries with \"medium\" burden of disease have between 2.75345 and 8.2127 DALYs; countries with \"high\" burden of disease have between 8.2127 and 26.699 DALYs; and countries with \"awful\" burden of diease have more than 26.699 DALYs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your goal is to train a decision tree classifier for the attribute “BurdenOfDisease\" using all other variables (except country name) as features with sklearn.tree.DecisionTreeClassifier. \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Please choose a train/test split and choose a hyper-parameter governing model simplicity, for example, the maximum tree depth or maximum number of leaf nodes. Then, fit your decision tree classifier (using the training set) for different values of this parameter and for each such value, record the corresponding classification accuracy on the test set. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# your code here\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3,random_state=0)\n",
    "Test_OS=[]\n",
    "for i in range(2,11):\n",
    "    dt=DecisionTreeClassifier(max_depth=i,random_state=0)\n",
    "    dt.fit(X_train,y_train)\n",
    "    Test_OS.append(dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a plot of accuracy vs. simplicity for different values of the hyper-parameter chosen in part a). That is, the x-axis should be hyper-parameter value (e.g. tree depth) and the y-axis should be accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAFNCAYAAACaFc8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2730c47bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# your code here\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(2,11),Test_OS)\n",
    "plt.xlabel(\"Max leaf nodes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Simplicity (max depth)\")\n",
    "plt.xlim(2,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Tune the hyper-parameter you choose in part a) by cross-validation using the training data. You can choose to use the GridSearchCV package from sklearn or write your own code to do cross-validation by spliting the training data into training and validation data. What is the out of sample accuracy after tuning the hyper-parameter? (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.813186813187\n",
      "Out sample: 0.615384615385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1,11)}\n",
    "dt=DecisionTreeClassifier()\n",
    "gr=GridSearchCV(dt,param_grid=param_grid,cv=5)\n",
    "rs=gr.fit(X_train,y_train)\n",
    "print(rs.best_params_)\n",
    "print(rs.score(X_train,y_train))\n",
    "print(\"Out sample: {}\".format(rs.score(X_test,y_test)))\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Visualize a simple decision tree (e.g., with max_depth = 2 or 3) learned from the data.  To do so, given your decision tree dt, you can use the code below, then copy and paste the resulting output into http://www.webgraphviz.com.  Alternatively, if you have graphviz installed on your machine, you can use that. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f3361fa6869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m thestring=tree.export_graphviz(dt,out_file=None,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# your code here\n",
    "dt=DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train,y_train)\n",
    "thestring=tree.export_graphviz(dt,out_file=None,\n",
    "                         feature_names=X_train.columns.values,  \n",
    "                         class_names=dt.classes_,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False).replace(\"<br/>\",\", \").replace(\"&le;\",\"<=\").replace(\"=<\",\"=\\\"\").replace(\">,\",\"\\\",\")\n",
    "print thestring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4, Fit a random forest to the data from question 3 (20 pts)\n",
    "\n",
    "a) Please use the same test/train split from previous question and feel free to tune the hyper-parameters for Random Forest model using training data. The package from sklearn is here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
    "Then please report your out of sample prediction result and compare this model's performance with 3c). (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 41}\n",
      "0.967032967033\n",
      "Out sample: 0.692307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators':range(1,51,5)}\n",
    "rf=RandomForestClassifier(n_jobs=-1,max_leaf_nodes=10)\n",
    "gr=GridSearchCV(rf,param_grid=param_grid,cv=5)\n",
    "rs=gr.fit(X_train,y_train)\n",
    "print(rs.best_params_)\n",
    "print(rs.score(X_train,y_train))\n",
    "print(\"Out sample: {}\".format(rs.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) Write one paragraph comparing the results from those two models (Random Forest vs Decision Tree) in terms of both accuracy and interpretability. (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Your answer here.\n",
    "\n",
    "Decision tree model predicts using if then this conditions. One of the main advantages of decision trees is its interpretability.It is possible to make straightforward viszualizatons that represent how a tree takes a decision when given an input. But decision trees are prone to overfitting espectially when the depth of the tree is large. Random Forest aggregate the results of several decision trees. This makes their accuracy higher but at the cost of interpretability.The Random Forest gives slightly higher out of sample accuracy bu this comes at the cost of interpretability. For both the models it can be seen that there is overfitting. The Random Forest does not give a significant improvement in performance from decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
